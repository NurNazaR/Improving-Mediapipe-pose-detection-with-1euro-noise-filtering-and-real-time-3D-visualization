{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "from mediapipe import solutions\n",
    "from mediapipe.framework.formats import landmark_pb2\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"pose_landmarker_full.task\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from time import time\n",
    "\n",
    "def smoothing_factor(t_e, cutoff):\n",
    "    r = 2 * np.pi * cutoff * t_e\n",
    "    return r / (r + 1)\n",
    "\n",
    "\n",
    "def exponential_smoothing(a, x, x_prev):\n",
    "    return a * x + (1 - a) * x_prev\n",
    "\n",
    "\n",
    "class OneEuroFilter:\n",
    "    def __init__(self, x0, dx0=0.0, min_cutoff=1.0, beta=0.0,\n",
    "                 d_cutoff=1.0):\n",
    "        \"\"\"Initialize the one euro filter.\"\"\"\n",
    "        # The parameters.\n",
    "        self.data_shape = x0.shape\n",
    "        self.min_cutoff = np.full(x0.shape, min_cutoff)\n",
    "        self.beta = np.full(x0.shape, beta)\n",
    "        self.d_cutoff = np.full(x0.shape, d_cutoff)\n",
    "        # Previous values.\n",
    "        self.x_prev = x0.astype(np.float64)\n",
    "        self.dx_prev = np.full(x0.shape, dx0)\n",
    "        self.t_prev = time()\n",
    "\n",
    "    def __call__(self, x):\n",
    "        \"\"\"Compute the filtered signal.\"\"\"\n",
    "        assert x.shape == self.data_shape\n",
    "\n",
    "        t = time()\n",
    "        t_e = t - self.t_prev\n",
    "        t_e = np.full(x.shape, t_e)\n",
    "\n",
    "        # The filtered derivative of the signal.\n",
    "        a_d = smoothing_factor(t_e, self.d_cutoff)\n",
    "        dx = (x - self.x_prev) / t_e\n",
    "        dx_hat = exponential_smoothing(a_d, dx, self.dx_prev)\n",
    "\n",
    "        # The filtered signal.\n",
    "        cutoff = self.min_cutoff + self.beta * np.abs(dx_hat)\n",
    "        a = smoothing_factor(t_e, cutoff)\n",
    "        x_hat = exponential_smoothing(a, x, self.x_prev)\n",
    "\n",
    "        # Memorize the previous values.\n",
    "        self.x_prev = x_hat\n",
    "        self.dx_prev = dx_hat\n",
    "        self.t_prev = t\n",
    "\n",
    "        return x_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_landmarks_on_image(rgb_image, detection_result):\n",
    "  pose_landmarks_list = detection_result.pose_landmarks\n",
    "  annotated_image = np.copy(rgb_image)\n",
    "\n",
    "  # Loop through the detected poses to visualize.\n",
    "  for idx in range(len(pose_landmarks_list)):\n",
    "    pose_landmarks = pose_landmarks_list[idx]\n",
    "    # Draw the pose landmarks.\n",
    "    pose_landmarks_proto = landmark_pb2.NormalizedLandmarkList()\n",
    "    pose_landmarks_proto.landmark.extend([\n",
    "      landmark_pb2.NormalizedLandmark(x=landmark.x, y=landmark.y, z=landmark.z) for landmark in pose_landmarks\n",
    "    ])\n",
    "    solutions.drawing_utils.draw_landmarks(\n",
    "      annotated_image,\n",
    "      pose_landmarks_proto,\n",
    "      solutions.pose.POSE_CONNECTIONS,\n",
    "      solutions.drawing_styles.get_default_pose_landmarks_style())\n",
    "  return annotated_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1712842586.128710       1 gl_context.cc:344] GL version: 2.1 (2.1 Metal - 83.1), renderer: Apple M2\n"
     ]
    }
   ],
   "source": [
    "BaseOptions = mp.tasks.BaseOptions\n",
    "PoseLandmarker = mp.tasks.vision.PoseLandmarker\n",
    "PoseLandmarkerOptions = mp.tasks.vision.PoseLandmarkerOptions\n",
    "VisionRunningMode = mp.tasks.vision.RunningMode\n",
    "\n",
    "options = PoseLandmarkerOptions(\n",
    "    base_options=BaseOptions(model_asset_path=model_path),\n",
    "    running_mode=VisionRunningMode.IMAGE)\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "with PoseLandmarker.create_from_options(options) as pose:\n",
    "    init = True\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        frame = cv2.flip(frame, 1)\n",
    "        # Recolor image to RGB\n",
    "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "      \n",
    "        # Make detection\n",
    "        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=image)\n",
    "        results = pose.detect(mp_image)\n",
    "        \n",
    "        if len(results.pose_landmarks) != 0:\n",
    "            coords = np.array([[joint.x, joint.y, joint.z] for joint in results.pose_landmarks[0]])\n",
    "            if init == True:\n",
    "                coords_hat = coords.copy()\n",
    "                \n",
    "                # The filtered signal\n",
    "                min_cutoff = 1\n",
    "                beta = 0\n",
    "                one_euro_filter = OneEuroFilter(\n",
    "                    coords,\n",
    "                    min_cutoff=min_cutoff,\n",
    "                    beta=beta)\n",
    "                init = False\n",
    "            else:\n",
    "                coords_hat = one_euro_filter(coords)\n",
    "                \n",
    "            for i in range(coords.shape[0]):\n",
    "                results.pose_landmarks[0][i].x = coords_hat[i][0]\n",
    "                results.pose_landmarks[0][i].y = coords_hat[i][1]\n",
    "                results.pose_landmarks[0][i].z = coords_hat[i][2]\n",
    "            \n",
    "            \n",
    "        # Recolor back to BGR\n",
    "        image.flags.writeable = True\n",
    "    \n",
    "        \n",
    "        annotated_image = draw_landmarks_on_image(image, results)\n",
    "        image = cv2.cvtColor(annotated_image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        cv2.imshow('Mediapipe Feed', image)\n",
    "        \n",
    "\n",
    "        if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    cv2.destroyAllWindows()\n",
    "    cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = np.array([[joint.x, joint.y, joint.z] for joint in results.pose_landmarks[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(coords.shape[0]):\n",
    "    results.pose_landmarks[0][i].x = coords_hat[i][0]\n",
    "    results.pose_landmarks[0][i].y = coords_hat[i][1]\n",
    "    results.pose_landmarks[0][i].z = coords_hat[i][2]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(33, 3)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coords.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords_hat = np.zeros((33, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The filtered signal\n",
    "min_cutoff = 0.004\n",
    "beta = 0.7\n",
    "df_hat = np.zeros(33, 3)\n",
    "df_hat[0] = df[0]\n",
    "one_euro_filter = OneEuroFilter(\n",
    "    df[0],\n",
    "    min_cutoff=min_cutoff,\n",
    "    beta=beta\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
